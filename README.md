# Точная интерполяция

## Интерполяция в лоб -- решение СЛАУ с определителем Ван дер Монда

См. функцию `naive_interpolation` в [accurate_interpolation.py](src/accurate_interpolation.py).
Через любые $N$ точек можно пропустить полином $N-1$ степени. Для этого составляется 
СЛАУ из уравнений для каждой точки, такая СЛАУ имеет своей матрицей матрицу Ван-Дер-Монда.

Функции `naive_interpolation` на вход подаётся массивы X и Y одинаковой размерности N,
на выход пока что получаем коэффициенты полинома степени $N-1$, начиная с нулевой степени.

Нужно:
- переписать эту функцию с numpy (численного решения) на sympy (в нём можно работать в обыкновенных дробях);
- переделать return, нужно возвращать sympy выражение, содержащее переменную `sp.Symbol('x')`.

## Интерполяция Лагранжа

См. функцию `lagrange_interpolation` в [accurate_interpolation.py](src/accurate_interpolation.py).

Метод `lagrange_interpolation(X, Y)`, принимая на вход те же массивы, возвращает уже
sympy выражение, содержащее `sp.Symbol('x')`. Такая функция хорошо выводится:
`sp.pretty(f)`, `sp.latex(f)` -- вернут строку с юникодовским рисунком формулы, или latex код.
Для подсчета этой функции в какой-либо точке, можно:
```Python
from src.accurate_interpolation import *
f = lagrange_interpolation([-1, 0, 1, 2], [1, -1, 2, -1])
f_lambda = sp.lambdify(sp.Symbol('x'), f)
print(f_lambda(1))
```

TODO:
- Расписать получше решение (внутри функции `lagrange_interpolation`).

## Интерполяция Ньютона (sympy)

См. функцию `newton_interpolation` в [accurate_interpolation.py](src/accurate_interpolation.py).

Функция схожа с `lagrange_interpolation`.

TODO:
- Расписать получше решение.

---

# Приближенная интерполяция
## Метод наименьших квадратов

См. функцию `mnk_interpolate` в [approx_interpolation.py](src/approx_interpolation.py).

[//]: # (Имеется некоторая функция, у которой мы знаем только набор значений функции. )

[//]: # ()
[//]: # (В ДЗ требуется для вычислений выбрать значения в концах отрезка и всех целых точек внутри него.)

Метод наименьших квадратов позволяет приблизить какую-либо (непрерывную) функцию
полиномом (не только полиномом) меньшей степени. Это достигается минимизацией суммы квадратов
разностей в точках. Функция `mnk_interpolate(X, Y, power=1)` работает схоже с точной интерполяцией,
но 
- X, Y -- np.array;
- можно указать степень полинома с помощью параметра `power`.

На выходе имеем numpy полином, работающий очень просто: если `f = mnk_interpolate(X, Y, 1)`,
то можно считать `f(1)`, `f([1, 2]) # == [f(1), f(2)]`.


--- 

# Одномерная оптимизация без использования производной

Ко всему файлу `src/extremum.py` TODO:
- Убрать использование глобальных переменных;
- Все функции реализованы рекурсивно, из-за этого хромает вывод, но несложно переписать на циклы.

## Метод деления отрезка _(почти)_ пополам

Зафиксируем $\delta = \mathrm{const} (=0.1)$.
- Полагаем $a_1 = a$, $b_1 = b$.  
- Выбираем две точки $u_1 = \frac{a + b - \delta}{2}$ и $u_2 = \frac{a + b + \delta}{2}$. 
- Если $f(u_1) \leq f(u_2)$, тогда функция возрастает, значит нужно выбрать левый подотрезок:
полагаем $a_2 = a_1$, $b_2 = u_2$. 
- Иначе, если $f(u_1) > f(u_2)$, тогда считаем, что $a_2 = u_1$, $b_2 = b_1$.
- Аналогично на каждой следующей итерации (рекурсивно вызываем ту же самую процедуру, но на меньшем подотрезке).

В дз необходимо выбрать минимум, а также точку минимума. 

См. функцию `bisect` в [extremum.py](src/extremum.py).

Использование: `bisect(f, a, b, iteration = 1, COUNT_ITERATIONS = 3)`, где 
`f` -- sympy выражение, содержащее переменную `sp.Symbol('x')`.


## Метод золотого сечения

Аналогично предыдущему методу, но вместо использования сомнительного параметра $\delta$,
$u_i$ выбираем с помощью константы $\varphi = \dfrac{1+\sqrt{5}}{2}$:
- Полагаем u1 = a + 0.382 * (b - a), u2 = a + 0.618 * (b - a). 

Если f(u1) <= f(u2), тогда a2 = a1, b2 = u2, bar_u2 = u1.

Инааче, если f(u1) > f(u2), тогда a2 = u1, b2 = b1, bar_u2 = u2.

Аналогично на каждой следующей итерации.

См. функцию `golden_cut` в [extremum.py](src/extremum.py). 

## Метод парабол 

- Полагаем $u_0 = x_0$, $u_1 = u_0 + h$. 

- Если точка $u_1 \in [a, b]$. Тогда вычисляем значение в ней. 

- Если $f(u_1) \leq f(u_0)$, то вычисляем $u_i = u_0 + 2^{i - 1} \cdot h, i \geq 2$.

- Если $u_i$ принадлежит отрезку, то вычисляем значение в ней. 

- Проверяем, образуют ли $u_{i - 2}$, $u_{i - 1}$, $u_{i}$ выпуклую тройку для $f(x)$. 

- Если не образуют, то берем следующую точку. Когда выпуклая тройка найдена, то проводим параболу ветвями вверх и ищем вершину параболы $w$. 

- Если $u_{i} \not \in [a, b]$ , а выпуклая тройка так и не найдена, тогда полагаем точкой минимума $w = b$. 

- Если $f(u_{1}) > f(u_0)$ или $u_{1}$ принадлежит отрезку, тогда изменим направление поиска. Переобозначим $u_{0} = u_{1}$, $u_{i} = u_{0} - 2^(i - 1) \cdot h, i \geq 1$.

- Если тройка найдена, w - вершина параболы, если нет $w = a$. 

- Далее $f(\bar{u}) = $\operatorname{min}(f(w), f(u_0), \dotsc, f(u_n))$.

См. функцию `parabola` в [extremum.py](src/extremum.py).

Использование `parabola(f, a, b)`, где `f` -- sympy выражение, содержащее переменную `sp.Symbol('x')`.

## Метод ломанных 

(пустая функция)

См. функцию `method_lomannih` в [extremum.py](src/extremum.py). 

# Одномерная оптимизация с использованием производных

## Метод средней точки

Положим $a_0 = a, b_0 = b$. Возьмем середину отрезка $[a, b]: c_0 = \frac{a_0 + b_0}{2}$. Вычислим $f'(c_0)$.
1. $f'(c_0) = 0 \Rightarrow c_0$ -- т. экстремума; 
2. $f'(c_0) > 0 \Rightarrow a_1 = a_0, b_1 = c_0$;
3. $f'(c_0) < 0 \Rightarrow a_1 = c_0, b_1 = b_0$.

Опишем $k$-й шаг:

$[a_{k - 1}, b_{k - 1}], c_k = \frac{a_{k-1} + b_{k-1}}{2}, f'(c_k)$

- $f'(c_k) = 0 \Rightarrow c_k$ -- стационарная точка;

- $f'(c_k) > 0 \Rightarrow a_k = a_{k - 1}, b_k = c_{k - 1}$;

- $f'(c_k) < 0 \Rightarrow a_k = c_{k - 1}, b_k = b_{k - 1}$.

$l([a_k, b_k]) = \frac{b - a}{2^k}$.

См. функцию `method_srednei_tochki` в [extremum_with_derivative.py](src/extremum_with_derivative.py).

Использование `method_srednei_tochki(f, diff_f, a, b, iteration = 1, COUNT_ITERATIONS = 3)`, где `f` -- sympy выражение, содержащее переменную `sp.Symbol('x')`.

## Метод хорд _(метод секущих)_

См. функцию `chordal_method` в [extremum_with_derivative.py](src/extremum_with_derivative.py).

## Метод Ньютона _(метод касательных)_

См. функцию `newton_method` в [extremum_with_two_derivatives.py](src/extremum_with_two_derivatives.py).

# Многомерная оптимизация 

## Градиентный метод дробления шага

См. функцию `grad_method_step_division` в [multidim_optimization_with_grad.py](src/multidim_optimization_with_grad.py).

## Градиентный метод скорейшего спуска

См. функцию `grad_method_of_fastest_fall` в [multidim_optimization_with_grad.py](src/multidim_optimization_with_grad.py).

## Метод сопряженных направлений

(нет)
